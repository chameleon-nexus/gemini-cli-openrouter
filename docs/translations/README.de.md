# Gemini CLI - OpenRouter Edition

[![npm version](https://badge.fury.io/js/%40chameleon-nexus-tech%2Fgemini-cli.svg)](https://badge.fury.io/js/%40chameleon-nexus-tech%2Fgemini-cli)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

**ğŸš€ Erweiterte Gemini CLI mit OpenRouter-UnterstÃ¼tzung - Zugriff auf 200+ KI-Modelle Ã¼ber eine Schnittstelle**

> âš ï¸ **Wichtiger Hinweis**: Dies ist eine modifizierte Version von [Google Gemini CLI](https://github.com/google-gemini/gemini-cli). Das Urheberrecht des ursprÃ¼nglichen Projekts gehÃ¶rt Google LLC unter Apache 2.0 Lizenz.

## ğŸŒŸ Projektstatus & zukÃ¼nftige Entwicklung

**Aktueller Status**: Dieses Projekt unterstÃ¼tzt derzeit eine kuratierte Auswahl hochperformanter Modelle durch OpenRouter-Integration. Wir arbeiten aktiv daran, die ModellkompatibilitÃ¤t zu erweitern und Funktionen zu verbessern.

**Community-getrieben**: Ihre UnterstÃ¼tzung hilft uns beim Wachstum! â­ Vergeben Sie einen Stern an dieses Repository und erwÃ¤gen Sie einen Beitrag, um uns zu helfen:
- UnterstÃ¼tzung fÃ¼r mehr KI-Modelle hinzufÃ¼gen
- Leistung und ZuverlÃ¤ssigkeit verbessern
- Neue Funktionen und Integrationen entwickeln
- Umfassende Dokumentation pflegen

**Mitmachen**: Haben Sie VorschlÃ¤ge oder mÃ¶chten Sie beitragen? Kontaktieren Sie uns unter **mythicscribe2014@gmail.com** - wir freuen uns auf Ihre Nachricht!

## ğŸŒ Sprachwechsel

| ğŸ‡ºğŸ‡¸ [English](../README.md) | ğŸ‡»ğŸ‡³ [Tiáº¿ng Viá»‡t](README.vi.md) | ğŸ‡¯ğŸ‡µ [æ—¥æœ¬èª](README.ja.md) | ğŸ‡©ğŸ‡ª **Deutsch** | ğŸ‡¸ğŸ‡¦ [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README.ar.md) | ğŸ‡¨ğŸ‡³ [ä¸­æ–‡](README.zh.md) |

## ğŸŒŸ Kernfunktionen

- ğŸ¯ **OpenRouter-Integration**: Zugriff auf 200+ KI-Modelle Ã¼ber OpenRouters einheitliche API
- ğŸ”„ **Modell-FlexibilitÃ¤t**: Einfacher Wechsel zwischen GPT-4, Claude, Llama, Mistral und vielen mehr
- ğŸŒ **Globale Modell-Abdeckung**: UnterstÃ¼tzt alle wichtigen KI-Modelle von OpenAI, Anthropic, Meta, Google und mehr
- ğŸ”§ **Einfache Konfiguration**: Ein API-SchlÃ¼ssel fÃ¼r alle Modelle
- ğŸ“Š **VollstÃ¤ndige FunktionalitÃ¤t**: Streaming/Non-Streaming, Token-ZÃ¤hlung, Funktionsaufrufe alle unterstÃ¼tzt
- ğŸš€ **Verbesserte Leistung**: Optimiert fÃ¼r OpenRouters hochperformante Infrastruktur

## ğŸ“¦ Installation

### ğŸš€ Schnelle Installation (Empfohlen)

```bash
npm install -g @chameleon-nexus-tech/gemini-cli-openrouter
```

### ğŸ“‹ Alternative Installationsmethoden

```bash
# Mit npm (Node.js Paketmanager)
npm install -g @chameleon-nexus-tech/gemini-cli-openrouter

# Mit yarn
yarn global add @chameleon-nexus-tech/gemini-cli-openrouter

# Mit pnpm
pnpm add -g @chameleon-nexus-tech/gemini-cli-openrouter
```

## ğŸ›ï¸ OpenRouter-Integration

### ğŸŒ OpenRouter - Ihr Gateway zu 200+ KI-Modellen

OpenRouter bietet Zugriff auf die weltweit fortschrittlichsten KI-Modelle Ã¼ber eine einzige, einheitliche API. Diese erweiterte Gemini CLI nutzt OpenRouter, um Ihnen sofortigen Zugriff zu geben auf:

**ğŸ”¥ Beliebte verfÃ¼gbare Modelle:**
- `openai/gpt-4o` (Standard) - OpenAIs leistungsstÃ¤rkstes Modell
- `openai/gpt-4` - OpenAIs Flaggschiff-Modell
- `openai/gpt-4-turbo` - Schnellere GPT-4-Variante
- `anthropic/claude-3.5-sonnet` - Anthropics leistungsstÃ¤rkstes Modell
- `meta-llama/llama-3.1-8b-instruct` - Metas neuestes Llama-Modell
- `meta-llama/llama-3.1-70b-instruct` - Metas leistungsstÃ¤rkstes Llama
- `mistralai/mistral-7b-instruct` - Mistrals effizientes Modell
- `mistralai/mixtral-8x7b-instruct` - Mixtrals Mixture of Experts
- `google/gemini-pro` - Googles Gemini-Modell
- `google/gemini-pro-vision` - Googles multimodales Modell
- `cohere/command-r-plus` - Coheres fortschrittliches Modell
- `deepseek/deepseek-coder` - Spezialisiertes Codierungsmodell
- Und 190+ weitere Modelle von fÃ¼hrenden KI-Unternehmen!

**ğŸ¯ Warum OpenRouter?**
- **Einzelner API-SchlÃ¼ssel**: Zugriff auf alle Modelle mit einer Anmeldedaten
- **Beste Preise**: WettbewerbsfÃ¤hige Preise bei allen Anbietern
- **Hohe VerfÃ¼gbarkeit**: 99,9% Uptime mit globaler Infrastruktur
- **Modell-Vergleich**: Einfacher Wechsel zwischen Modellen zum Testen
- **Enterprise-Features**: Rate-Limiting, Nutzungsanalysen und mehr

## âš™ï¸ Konfiguration

### ğŸ”§ Erforderliche Umgebungsvariablen

Sie mÃ¼ssen nur diese **4 Umgebungsvariablen** setzen, um zu beginnen:

```bash
# 1. KI-Engine auf OpenRouter setzen
export AI_ENGINE="openrouter"

# 2. Ihren OpenRouter API-SchlÃ¼ssel setzen (von https://openrouter.ai/keys erhalten)
export AI_API_KEY="your-openrouter-api-key"

# 3. Ihr bevorzugtes Modell wÃ¤hlen
export AI_MODEL="openai/gpt-4o"

# 4. Beliebigen Wert setzen, um Gemini API-Validierung zu Ã¼berspringen
export GEMINI_API_KEY="any-value-here"
```

### ğŸªŸ Windows PowerShell-Konfiguration

```powershell
# Die 4 erforderlichen Umgebungsvariablen setzen
$env:AI_ENGINE="openrouter"
$env:AI_API_KEY="your-openrouter-api-key"
$env:AI_MODEL="openai/gpt-4o"
$env:GEMINI_API_KEY="any-value-here"
```

### ğŸ¯ Schnelle Einrichtung

Das war's! Diese 4 Variablen sind alles, was Sie brauchen:
- `AI_ENGINE="openrouter"` - Teilt dem System mit, OpenRouter zu verwenden
- `AI_API_KEY="your-key"` - Ihr OpenRouter API-SchlÃ¼ssel
- `AI_MODEL="model-name"` - Das KI-Modell, das Sie verwenden mÃ¶chten
- `GEMINI_API_KEY="anything"` - Auf beliebigen Wert setzen, um Validierung zu Ã¼berspringen

## ğŸš€ Verwendung

### ğŸ’¬ Direkter Frage-Modus

```bash
gemini "Hallo, bitte stellen Sie sich vor"
```

### ğŸ”„ Interaktiver Modus

```bash
gemini
```

Dann wÃ¤hlen Sie "2. Use Gemini API Key" und drÃ¼cken Enter, um mit dem Chatten zu beginnen.

## ğŸ§ª Modell-Testbeispiele

### ğŸŒ Testen mit GPT-4o

```bash
# Die 4 erforderlichen Umgebungsvariablen setzen
export AI_ENGINE="openrouter"
export AI_API_KEY="your-openrouter-api-key"
export AI_MODEL="openai/gpt-4o"
export GEMINI_API_KEY="any-value-here"

# Test-Befehl
gemini "Hallo, bitte stellen Sie sich vor und sagen Sie mir, welches KI-Modell Sie sind."
```

## ğŸ—ï¸ Technische Architektur

### ğŸ¯ OpenRouter-Integrationsarchitektur

Dieses Projekt verfÃ¼gt Ã¼ber eine **spezialisierte OpenRouter-Integration**, die nahtlosen Zugriff auf 200+ KI-Modelle bietet:

```
OpenRouter-Integration
â”œâ”€â”€ OpenrouterContentGenerator    (PrimÃ¤rer OpenRouter-Adapter)
â”œâ”€â”€ ContentGeneratorFactory       (Engine-Auswahl und -verwaltung)
â”œâ”€â”€ Tool-AusfÃ¼hrungssystem        (Funktionsaufruf-UnterstÃ¼tzung)
â””â”€â”€ Streaming-Antwort-Handler      (Echtzeit-Antwortverarbeitung)
```

### ğŸ”§ Kernfunktionen

âœ… **OpenRouter-Integration**: Direkter Zugriff auf 200+ KI-Modelle Ã¼ber OpenRouters einheitliche API  
âœ… **Modell-FlexibilitÃ¤t**: Einfacher Wechsel zwischen verschiedenen KI-Modellen mit einer einzigen Umgebungsvariable  
âœ… **Automatische Formatkonvertierung**: Nahtlose Konvertierung zwischen Gemini-Format und OpenRouter API-Format  
âœ… **Streaming-Antwort-UnterstÃ¼tzung**: Echtzeit-Streaming-Antworten fÃ¼r alle unterstÃ¼tzten Modelle  
âœ… **Funktionsaufrufe**: VollstÃ¤ndige UnterstÃ¼tzung fÃ¼r Tool-/Funktionsaufrufe Ã¼ber alle Modelle  
âœ… **Intelligente Fehlerbehandlung**: Umfassende Fehlerbehandlung mit detaillierten Nachrichten  
âœ… **KonfigurationsprioritÃ¤t**: OpenRouter-spezifische Konfiguration > Einheitliche Konfiguration > Standardkonfiguration  

### ğŸ“ Kern-Dateistruktur

```
packages/core/src/core/
â”œâ”€â”€ contentGenerator.ts              # ContentGenerator-Interface-Definition
â”œâ”€â”€ contentGeneratorFactory.ts       # Engine-Factory mit OpenRouter-PrioritÃ¤t
â”œâ”€â”€ openrouterContentGenerator.ts    # OpenRouter-Adapter (primÃ¤r)
â”œâ”€â”€ coreToolScheduler.ts            # Tool-AusfÃ¼hrung und Funktionsaufrufe
â””â”€â”€ [andere Adapter]                 # ZusÃ¤tzliche Engine-UnterstÃ¼tzung
```

### ğŸ”„ OpenRouter API-Integration

**Anfrage-Konvertierungsfluss**:
```
Gemini-Anfrage â†’ OpenRouter-Adapter â†’ OpenRouter API â†’ 200+ KI-Modelle
```

**Antwort-Konvertierungsfluss**:
```
KI-Modell-Antwort â†’ OpenRouter API â†’ OpenRouter-Adapter â†’ Gemini-Antwortformat
```

**UnterstÃ¼tzte OpenRouter-Funktionen**:
- **Modellauswahl**: Einfacher Wechsel zwischen 200+ Modellen
- **Funktionsaufrufe**: VollstÃ¤ndige Tool-/Funktionsaufruf-UnterstÃ¼tzung
- **Streaming**: Echtzeit-Antwort-Streaming
- **Token-ZÃ¤hlung**: Automatische Token-Nutzungsverfolgung
- **Fehlerbehandlung**: Umfassende Fehlerverwaltung
- **Rate-Limiting**: Eingebaute Rate-Limiting und Wiederholungslogik

## ğŸ“‹ Lizenz-Compliance

Dieses Projekt basiert auf [Google Gemini CLI](https://github.com/google-gemini/gemini-cli) und folgt den Apache 2.0 Lizenz-Anforderungen:

### UrsprÃ¼ngliche Projektinformationen

- **UrsprÃ¼ngliches Projekt**: Google Gemini CLI
- **UrsprÃ¼ngliches Urheberrecht**: Copyright 2025 Google LLC  
- **UrsprÃ¼ngliche Lizenz**: Apache License 2.0
- **UrsprÃ¼ngliches Repository**: https://github.com/google-gemini/gemini-cli

### Ã„nderungsaussage

In Ãœbereinstimmung mit Apache 2.0 Lizenz Abschnitt 4:

- âœ… UrsprÃ¼ngliche Apache 2.0 Lizenz beibehalten
- âœ… UrsprÃ¼ngliche Urheberrechtshinweise beibehalten
- âœ… Ã„nderungen klar markiert
- âœ… VollstÃ¤ndigen Lizenztext eingefÃ¼gt

## ğŸ”„ Migration von der ursprÃ¼nglichen Gemini CLI

Wenn Sie von der ursprÃ¼nglichen Google Gemini CLI migrieren:

1. **UrsprÃ¼ngliche Version deinstallieren**: `npm uninstall -g @google/gemini-cli`
2. **Diese Version installieren**: `npm install -g @chameleon-nexus-tech/gemini-cli`
3. **OpenRouter API-SchlÃ¼ssel erhalten**: Bei [OpenRouter](https://openrouter.ai/keys) anmelden
4. **Die 4 erforderlichen Umgebungsvariablen setzen**:
```bash
   export AI_ENGINE="openrouter"
   export AI_API_KEY="your-openrouter-api-key"
   export AI_MODEL="openai/gpt-4o"
   export GEMINI_API_KEY="any-value-here"
   ```
5. **Wie zuvor verwenden**: Alle Befehle bleiben gleich, jetzt mit Zugriff auf 200+ Modelle!

## ğŸ§ª OpenRouter-Integration testen

### ğŸš€ Schnelles Test-Skript

Erstellen Sie ein einfaches Test-Skript, um Ihre OpenRouter-Einrichtung zu Ã¼berprÃ¼fen:

```bash
#!/bin/bash
# test-openrouter.sh

# Die 4 erforderlichen Umgebungsvariablen setzen
export AI_ENGINE="openrouter"
export AI_API_KEY="your-openrouter-api-key"
export AI_MODEL="openai/gpt-4o"
export GEMINI_API_KEY="any-value-here"

echo "OpenRouter mit GPT-4o testen..."
gemini "Hallo, bitte stellen Sie sich vor und sagen Sie mir, welches KI-Modell Sie sind."
```

### ğŸ”§ Modell-Vergleichstest

Testen Sie verschiedene Modelle, um ihre Antworten zu vergleichen:

```bash
#!/bin/bash
# compare-models.sh

# Basis-Konfiguration einrichten (einmal setzen)
export AI_ENGINE="openrouter"
export AI_API_KEY="your-openrouter-api-key"
export GEMINI_API_KEY="any-value-here"

# GPT-4o testen
echo "=== GPT-4o testen ==="
export AI_MODEL="openai/gpt-4o"
gemini "Schreiben Sie ein Haiku Ã¼ber kÃ¼nstliche Intelligenz."
```

## ğŸ”— Verwandte Links

- [UrsprÃ¼ngliches Projekt (Google Gemini CLI)](https://github.com/google-gemini/gemini-cli)
- [OpenRouter](https://openrouter.ai/) - Zugriff auf 200+ KI-Modelle
- [OpenRouter API-Dokumentation](https://openrouter.ai/docs)
- [OpenRouter-Modellliste](https://openrouter.ai/models)
- [Apache 2.0 Lizenz](https://www.apache.org/licenses/LICENSE-2.0)

## ğŸ› Problemberichterstattung

Wenn Sie Probleme haben, melden Sie diese bitte bei [GitHub Issues](https://github.com/chameleon-nexus/gemini-cli/issues).

## ğŸ¤ Beitragen

BeitrÃ¤ge sind willkommen! Bitte stellen Sie sicher:

1. Dem Code-Stil des ursprÃ¼nglichen Projekts folgen
2. Angemessene Tests einschlieÃŸen
3. Relevante Dokumentation aktualisieren
4. Apache 2.0 Lizenz-Bedingungen respektieren

## ğŸŒŸ Projekt-Highlights

- ğŸš€ **OpenRouter-Integration**: Direkter Zugriff auf 200+ KI-Modelle Ã¼ber eine API
- ğŸ¯ **Modell-FlexibilitÃ¤t**: Einfacher Wechsel zwischen GPT-4, Claude, Llama und mehr
- ğŸ”„ **Einfache Konfiguration**: Ein API-SchlÃ¼ssel fÃ¼r alle Modelle
- ğŸŒ **Globale Abdeckung**: Zugriff auf Modelle von OpenAI, Anthropic, Meta, Google und mehr
- ğŸ“Š **Enterprise-Grade**: VollstÃ¤ndige Fehlerbehandlung und Konfigurationsverwaltung
- ğŸ”§ **Funktionsaufrufe**: VollstÃ¤ndige UnterstÃ¼tzung fÃ¼r Tool-/Funktionsaufrufe Ã¼ber alle Modelle

---

**Haftungsausschluss**: Dieses Projekt steht nicht in Verbindung mit Google oder OpenRouter. Bitte beachten Sie die Nutzungsbedingungen der jeweiligen Plattformen bei der Verwendung dieser Software.