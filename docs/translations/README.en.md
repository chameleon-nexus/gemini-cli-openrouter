# Gemini CLI - OpenRouter Edition

[![npm version](https://badge.fury.io/js/%40chameleon-nexus-tech%2Fgemini-cli.svg)](https://badge.fury.io/js/%40chameleon-nexus-tech%2Fgemini-cli)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

**ğŸš€ Enhanced Gemini CLI with OpenRouter Support - Access 200+ AI Models Through One Interface**

> âš ï¸ **Important Notice**: This is a modified version of [Google Gemini CLI](https://github.com/google-gemini/gemini-cli). Original project copyright belongs to Google LLC under Apache 2.0 License.

## ğŸŒ Language Switch

| ğŸ‡ºğŸ‡¸ **English** | ğŸ‡»ğŸ‡³ [Tiáº¿ng Viá»‡t](README.vi.md) | ğŸ‡¯ğŸ‡µ [æ—¥æœ¬èª](README.ja.md) | ğŸ‡©ğŸ‡ª [Deutsch](README.de.md) | ğŸ‡¸ğŸ‡¦ [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README.ar.md) | ğŸ‡¨ğŸ‡³ [ä¸­æ–‡](README.zh.md) |

## ğŸŒŸ Core Features

- ğŸ¯ **OpenRouter Integration**: Access 200+ AI models through OpenRouter's unified API
- ğŸ”„ **Model Flexibility**: Switch between GPT-4, Claude, Llama, Mistral, and many more
- ğŸŒ **Global Model Coverage**: Supports all major AI models from OpenAI, Anthropic, Meta, Google, and more
- ğŸ”§ **Simple Configuration**: Single API key for all models
- ğŸ“Š **Complete Functionality**: Streaming/non-streaming, token counting, function calling all supported
- ğŸš€ **Enhanced Performance**: Optimized for OpenRouter's high-performance infrastructure

## ğŸ“¦ Installation

```bash
npm install -g @chameleon-nexus-tech/gemini-cli
```

## ğŸ›ï¸ OpenRouter Integration

### ğŸŒ OpenRouter - Your Gateway to 200+ AI Models

OpenRouter provides access to the world's most advanced AI models through a single, unified API. This enhanced Gemini CLI leverages OpenRouter to give you instant access to:

**ğŸ”¥ Popular Models Available:**
- `openai/gpt-4o` (default) - OpenAI's most powerful model
- `openai/gpt-4` - OpenAI's flagship model
- `openai/gpt-4-turbo` - Faster GPT-4 variant
- `anthropic/claude-3.5-sonnet` - Anthropic's most capable model
- `meta-llama/llama-3.1-8b-instruct` - Meta's latest Llama model
- `meta-llama/llama-3.1-70b-instruct` - Meta's most powerful Llama
- `mistralai/mistral-7b-instruct` - Mistral's efficient model
- `mistralai/mixtral-8x7b-instruct` - Mixtral's mixture of experts
- `google/gemini-pro` - Google's Gemini model
- `google/gemini-pro-vision` - Google's multimodal model
- `cohere/command-r-plus` - Cohere's advanced model
- `deepseek/deepseek-coder` - Specialized coding model
- And 190+ more models from leading AI companies!

**ğŸ¯ Why OpenRouter?**
- **Single API Key**: Access all models with one credential
- **Best Pricing**: Competitive rates across all providers
- **High Availability**: 99.9% uptime with global infrastructure
- **Model Comparison**: Easy switching between models for testing
- **Enterprise Features**: Rate limiting, usage analytics, and more

## âš™ï¸ Configuration

### ğŸ”§ Required Environment Variables

You only need to set these **4 environment variables** to get started:

```bash
# 1. Set AI engine to OpenRouter
export AI_ENGINE="openrouter"

# 2. Set your OpenRouter API key (get from https://openrouter.ai/keys)
export AI_API_KEY="your-openrouter-api-key"

# 3. Choose your preferred model
export AI_MODEL="openai/gpt-4o"

# 4. Set any value to skip Gemini API validation
export GEMINI_API_KEY="any-value-here"
```

### ğŸªŸ Windows PowerShell Configuration

```powershell
# Set the 4 required environment variables
$env:AI_ENGINE="openrouter"
$env:AI_API_KEY="your-openrouter-api-key"
$env:AI_MODEL="openai/gpt-4o"
$env:GEMINI_API_KEY="any-value-here"
```

### ğŸ¯ Quick Setup

That's it! These 4 variables are all you need:
- `AI_ENGINE="openrouter"` - Tells the system to use OpenRouter
- `AI_API_KEY="your-key"` - Your OpenRouter API key
- `AI_MODEL="model-name"` - The AI model you want to use
- `GEMINI_API_KEY="anything"` - Set to any value to skip validation

## ğŸš€ Usage

### ğŸ’¬ Direct Question Mode

```bash
gemini "Hello, please introduce yourself"
```

### ğŸ”„ Interactive Mode

```bash
gemini
```

Then select "2. Use Gemini API Key" and press Enter to start chatting.

## ğŸ§ª Model Testing Examples

### ğŸŒ Testing with GPT-4o

```bash
# Set the 4 required environment variables
export AI_ENGINE="openrouter"
export AI_API_KEY="your-openrouter-api-key"
export AI_MODEL="openai/gpt-4o"
export GEMINI_API_KEY="any-value-here"

# Test command
gemini "Hello, please introduce yourself and tell me which AI model you are."
```

## ğŸ—ï¸ Technical Architecture

### ğŸ¯ OpenRouter Integration Architecture

This project features a **specialized OpenRouter integration** that provides seamless access to 200+ AI models:

```
OpenRouter Integration
â”œâ”€â”€ OpenrouterContentGenerator    (Primary OpenRouter adapter)
â”œâ”€â”€ ContentGeneratorFactory       (Engine selection and management)
â”œâ”€â”€ Tool Execution System        (Function calling support)
â””â”€â”€ Streaming Response Handler    (Real-time response processing)
```

### ğŸ”§ Core Features

âœ… **OpenRouter Integration**: Direct access to 200+ AI models through OpenRouter's unified API  
âœ… **Model Flexibility**: Easy switching between different AI models with a single environment variable  
âœ… **Automatic Format Conversion**: Seamless conversion between Gemini format and OpenRouter API format  
âœ… **Streaming Response Support**: Real-time streaming responses for all supported models  
âœ… **Function Calling**: Full support for tool/function calling across all models  
âœ… **Intelligent Error Handling**: Comprehensive error handling with detailed messages  
âœ… **Configuration Priority**: OpenRouter-specific config > Unified config > Default config  

### ğŸ“ Core File Structure

```
packages/core/src/core/
â”œâ”€â”€ contentGenerator.ts              # ContentGenerator interface definition
â”œâ”€â”€ contentGeneratorFactory.ts       # Engine factory with OpenRouter priority
â”œâ”€â”€ openrouterContentGenerator.ts    # OpenRouter adapter (primary)
â”œâ”€â”€ coreToolScheduler.ts            # Tool execution and function calling
â””â”€â”€ [other adapters]                 # Additional engine support
```

### ğŸ”„ OpenRouter API Integration

**Request Conversion Flow**:
```
Gemini Request â†’ OpenRouter Adapter â†’ OpenRouter API â†’ 200+ AI Models
```

**Response Conversion Flow**:
```
AI Model Response â†’ OpenRouter API â†’ OpenRouter Adapter â†’ Gemini Response Format
```

**Supported OpenRouter Features**:
- **Model Selection**: Easy switching between 200+ models
- **Function Calling**: Full tool/function calling support
- **Streaming**: Real-time response streaming
- **Token Counting**: Automatic token usage tracking
- **Error Handling**: Comprehensive error management
- **Rate Limiting**: Built-in rate limiting and retry logic

## ğŸ“‹ License Compliance

This project is based on [Google Gemini CLI](https://github.com/google-gemini/gemini-cli) and follows Apache 2.0 License requirements:

### Original Project Information

- **Original Project**: Google Gemini CLI
- **Original Copyright**: Copyright 2025 Google LLC  
- **Original License**: Apache License 2.0
- **Original Repository**: https://github.com/google-gemini/gemini-cli

### Modification Statement

In accordance with Apache 2.0 License Section 4:

- âœ… Retained original Apache 2.0 license
- âœ… Retained original copyright notices
- âœ… Clearly marked modifications
- âœ… Included complete license text

## ğŸ”„ Migration from Original Gemini CLI

If you're migrating from the original Google Gemini CLI:

1. **Uninstall original version**: `npm uninstall -g @google/gemini-cli`
2. **Install this version**: `npm install -g @chameleon-nexus-tech/gemini-cli`
3. **Get OpenRouter API key**: Sign up at [OpenRouter](https://openrouter.ai/keys)
4. **Set the 4 required environment variables**:
   ```bash
   export AI_ENGINE="openrouter"
   export AI_API_KEY="your-openrouter-api-key"
   export AI_MODEL="openai/gpt-4o"
   export GEMINI_API_KEY="any-value-here"
   ```
5. **Use as before**: All commands remain the same, now with access to 200+ models!

## ğŸ§ª Testing OpenRouter Integration

### ğŸš€ Quick Test Script

Create a simple test script to verify your OpenRouter setup:

```bash
#!/bin/bash
# test-openrouter.sh

# Set the 4 required environment variables
export AI_ENGINE="openrouter"
export AI_API_KEY="your-openrouter-api-key"
export AI_MODEL="openai/gpt-4o"
export GEMINI_API_KEY="any-value-here"

echo "Testing OpenRouter with GPT-4o..."
gemini "Hello, please introduce yourself and tell me which AI model you are."
```

### ğŸ”§ Model Comparison Test

Test different models to compare their responses:

```bash
#!/bin/bash
# compare-models.sh

# Set up the base configuration (set once)
export AI_ENGINE="openrouter"
export AI_API_KEY="your-openrouter-api-key"
export GEMINI_API_KEY="any-value-here"

# Test GPT-4o
echo "=== Testing GPT-4o ==="
export AI_MODEL="openai/gpt-4o"
gemini "Write a haiku about artificial intelligence."
```

## ğŸ”— Related Links

- [Original Project (Google Gemini CLI)](https://github.com/google-gemini/gemini-cli)
- [OpenRouter](https://openrouter.ai/) - Access 200+ AI models
- [OpenRouter API Documentation](https://openrouter.ai/docs)
- [OpenRouter Model List](https://openrouter.ai/models)
- [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0)

## ğŸ› Issue Reporting

If you encounter any issues, please report them on [GitHub Issues](https://github.com/chameleon-nexus/gemini-cli/issues).

## ğŸ¤ Contributing

Contributions are welcome! Please ensure:

1. Follow the original project's code style
2. Include appropriate tests
3. Update relevant documentation
4. Respect the Apache 2.0 license terms

## ğŸŒŸ Project Highlights

- ğŸš€ **OpenRouter Integration**: Direct access to 200+ AI models through one API
- ğŸ¯ **Model Flexibility**: Easy switching between GPT-4, Claude, Llama, and more
- ğŸ”„ **Simple Configuration**: Single API key for all models
- ğŸŒ **Global Coverage**: Access to models from OpenAI, Anthropic, Meta, Google, and more
- ğŸ“Š **Enterprise Grade**: Complete error handling and configuration management
- ğŸ”§ **Function Calling**: Full support for tool/function calling across all models

---

**Disclaimer**: This project is not affiliated with Google or OpenRouter. Please comply with the terms of service of the respective platforms when using this software.