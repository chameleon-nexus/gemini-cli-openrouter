/**
 * @license
 * Copyright 2025 Google LLC
 * SPDX-License-Identifier: Apache-2.0
 * 
 * Modified by Chameleon Nexus Tech
 * This file has been modified to add Azure OpenAI integration support.
 * Original work: Google Gemini CLI
 * Modifications: Added Azure OpenAI API adapter and format conversion
 */

import type {
  CountTokensParameters,
  CountTokensResponse,
  EmbedContentParameters,
  EmbedContentResponse,
  GenerateContentParameters,
  GenerateContentResponse,
} from '@google/genai';
import type { ContentGenerator } from './contentGenerator.js';

/**
 * Azure OpenAI ContentGenerator implementation
 * æ”¯æŒé€šè¿‡Azure OpenAIæœåŠ¡è®¿é—®GPTç³»åˆ—æ¨¡å‹
 */
export class AzureContentGenerator implements ContentGenerator {
  private readonly baseUrl: string;
  private readonly apiKey: string;
  private readonly model: string;
  private readonly apiVersion: string;

  constructor() {
    // ç»Ÿä¸€ç¯å¢ƒå˜é‡æ”¯æŒï¼Œä¼˜å…ˆä½¿ç”¨å¼•æ“ç‰¹å®šå˜é‡ï¼Œfallbackåˆ°é€šç”¨å˜é‡
    this.baseUrl = process.env['AZURE_BASE_URL'] || process.env['AI_BASE_URL'] || (() => {
      throw new Error('Base URL not found. Please set one of: AZURE_BASE_URL or AI_BASE_URL environment variable.\n' +
        'Supported formats:\n' +
        '  - Azure OpenAI: https://your-resource-name.openai.azure.com\n' +
        '  - Azure AI Foundry: https://your-resource-name.services.ai.azure.com');
    })();
    this.apiKey = process.env['AZURE_API_KEY'] || process.env['AI_API_KEY'] || (() => {
      throw new Error('API key not found. Please set one of: AZURE_API_KEY or AI_API_KEY environment variable.\n' +
        'For Azure OpenAI: Get your API key from Azure OpenAI Studio\n' +
        'For Azure AI Foundry: Use "az account get-access-token --scope https://ai.azure.com/.default"');
    })();
    this.model = process.env['AZURE_MODEL'] || process.env['AI_MODEL'] || 'gpt-4';
    this.apiVersion = process.env['AZURE_API_VERSION'] || process.env['AI_API_VERSION'] || '2024-10-21';
    
    // éªŒè¯Base URLæ ¼å¼
    if (!this.baseUrl.includes('openai.azure.com') && !this.baseUrl.includes('services.ai.azure.com')) {
      console.warn('âš ï¸  Warning: Base URL format may be incorrect. Expected formats:\n' +
        '  - Azure OpenAI: https://your-resource-name.openai.azure.com\n' +
        '  - Azure AI Foundry: https://your-resource-name.services.ai.azure.com');
    }
    
    console.log('â˜ï¸ Azure OpenAI ContentGenerator: Initialized successfully');
    console.log(`   Model: ${this.model} (deployment name)`);
    console.log(`   API Endpoint: ${this.baseUrl}`);
    console.log(`   API Version: ${this.apiVersion}`);
    console.log(`   Note: Model name should match your Azure deployment name`);
  }

  async generateContent(
    request: GenerateContentParameters,
    userPromptId: string,
  ): Promise<GenerateContentResponse> {
    try {
      // è½¬æ¢è¯·æ±‚æ ¼å¼
      const messages = this.convertGeminiToAzure(request.contents);
      
      const azureRequest = {
        messages,
        temperature: request.config?.temperature,
        max_tokens: request.config?.maxOutputTokens,
        top_p: request.config?.topP,
        stream: false
      };

      // è°ƒç”¨Azure OpenAI API
      const headers: Record<string, string> = {
        'Content-Type': 'application/json',
      };

      // æ”¯æŒä¸¤ç§è®¤è¯æ–¹å¼ï¼šapi-key å’Œ Bearer token
      if (this.baseUrl.includes('services.ai.azure.com')) {
        // Azure AI Foundry ä½¿ç”¨ Bearer token
        headers['authorization'] = `Bearer ${this.apiKey}`;
      } else {
        // Azure OpenAI ä½¿ç”¨ api-key
        headers['api-key'] = this.apiKey;
      }

      const response = await fetch(`${this.baseUrl}/openai/deployments/${this.model}/chat/completions?api-version=${this.apiVersion}`, {
        method: 'POST',
        headers,
        body: JSON.stringify(azureRequest),
        signal: request.config?.abortSignal
      });

      if (!response.ok) {
        const errorText = await response.text();
        let errorMessage = `Azure OpenAI API error: ${response.status} ${response.statusText}`;
        
        try {
          const errorJson = JSON.parse(errorText);
          if (errorJson.error?.message) {
            errorMessage += `\nDetails: ${errorJson.error.message}`;
          }
          if (errorJson.error?.code) {
            errorMessage += `\nError Code: ${errorJson.error.code}`;
          }
        } catch {
          errorMessage += `\nResponse: ${errorText}`;
        }
        
        // æä¾›å¸¸è§é”™è¯¯çš„è§£å†³å»ºè®®
        if (response.status === 401) {
          errorMessage += '\n\nğŸ’¡ è§£å†³å»ºè®®:\n' +
            '  - Azure OpenAI: æ£€æŸ¥AZURE_API_KEYæ˜¯å¦æ­£ç¡®\n' +
            '  - Azure AI Foundry: æ£€æŸ¥AZURE_API_KEYæ˜¯å¦ä¸ºæœ‰æ•ˆçš„è®¿é—®ä»¤ç‰Œ';
        } else if (response.status === 404) {
          errorMessage += '\n\nğŸ’¡ è§£å†³å»ºè®®:\n' +
            '  - æ£€æŸ¥AZURE_BASE_URLæ ¼å¼æ˜¯å¦æ­£ç¡®\n' +
            '  - æ£€æŸ¥æ¨¡å‹éƒ¨ç½²åç§°æ˜¯å¦ä¸AZURE_MODELåŒ¹é…\n' +
            '  - ç¡®è®¤éƒ¨ç½²å·²åˆ›å»ºå¹¶å¤„äºæ´»è·ƒçŠ¶æ€';
        } else if (response.status === 429) {
          errorMessage += '\n\nğŸ’¡ è§£å†³å»ºè®®: è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥é…é¢é™åˆ¶';
        }
        
        throw new Error(errorMessage);
      }

      const azureResponse = await response.json();
      
      // è½¬æ¢å“åº”æ ¼å¼
      return this.convertAzureToGemini(azureResponse);

    } catch (error) {
      console.error('Azure OpenAI API call failed:', error);
      throw error;
    }
  }

  async generateContentStream(
    request: GenerateContentParameters,
    userPromptId: string,
  ): Promise<AsyncGenerator<GenerateContentResponse>> {
    // å¯¹äºæµå¼å“åº”ï¼Œå…ˆå®ç°éæµå¼ç‰ˆæœ¬ç„¶åæ¨¡æ‹Ÿæµå¼è¾“å‡º
    const response = await this.generateContent(request, userPromptId);
    return this.simulateStream(response);
  }

  async countTokens(request: CountTokensParameters): Promise<CountTokensResponse> {
    // Azure OpenAIé€šè¿‡tiktokenåº“è®¡ç®—tokenï¼Œè¿™é‡Œä½¿ç”¨ä¼°ç®—æ–¹æ³•
    // åœ¨å®é™…ä½¿ç”¨ä¸­ï¼ŒAzure OpenAIä¼šåœ¨å“åº”ä¸­è¿”å›å‡†ç¡®çš„tokenç»Ÿè®¡
    try {
      const messages = this.convertGeminiToAzure(request.contents);
      const text = messages.map(m => m.content).join(' ');
      
      // æ›´ç²¾ç¡®çš„tokenä¼°ç®—ï¼ˆåŸºäºOpenAIçš„tiktokenç®—æ³•è¿‘ä¼¼ï¼‰
      const estimatedTokens = Math.ceil(text.length * 0.25); // å¹³å‡æ¯ä¸ªtokençº¦4ä¸ªå­—ç¬¦
      
      return {
        totalTokens: estimatedTokens,
      };
    } catch (error) {
      console.warn('Azure OpenAI token counting failed, using basic estimation:', error);
      
      // åŸºç¡€ä¼°ç®—å›é€€
      const text = JSON.stringify(request);
      const estimatedTokens = Math.ceil(text.length / 4);
      
      return {
        totalTokens: estimatedTokens,
      };
    }
  }

  async embedContent(request: EmbedContentParameters): Promise<EmbedContentResponse> {
    throw new Error('Embedding not supported by Azure OpenAI implementation');
  }

  private convertGeminiToAzure(contents: any): Array<{role: string, content: string}> {
    const messages: Array<{role: string, content: string}> = [];
    
    for (const content of contents) {
      if (content.parts && Array.isArray(content.parts)) {
        let textContent = '';
        
        for (const part of content.parts) {
          if (part.text) {
            textContent += part.text;
          }
        }
        
        if (textContent.trim()) {
          const role = content.role === 'model' ? 'assistant' : content.role;
          messages.push({
            role,
            content: textContent,
          });
        }
      }
    }
    
    return messages;
  }

  private convertAzureToGemini(azureResponse: any): any {
    const choice = azureResponse.choices[0];
    const message = choice.message;
    
    return {
      candidates: [{
        content: {
          role: 'model',
          parts: [{ text: message.content }],
        },
        finishReason: 'STOP' as any,
        index: choice.index,
      }],
      usageMetadata: {
        promptTokenCount: azureResponse.usage.prompt_tokens,
        candidatesTokenCount: azureResponse.usage.completion_tokens,
        totalTokenCount: azureResponse.usage.total_tokens,
      },
    } as GenerateContentResponse;
  }

  private async* simulateStream(response: GenerateContentResponse): AsyncGenerator<GenerateContentResponse> {
    const content = response.candidates?.[0]?.content?.parts?.[0]?.text || '';
    const words = content.split(' ');
    const chunkSize = 5; // æ¯æ¬¡è¿”å›5ä¸ªå•è¯

    for (let i = 0; i < words.length; i += chunkSize) {
      const chunk = words.slice(i, i + chunkSize).join(' ');
      
      yield {
        candidates: [{
          content: {
            role: 'model',
            parts: [{ text: chunk + (i + chunkSize < words.length ? ' ' : '') }],
          },
          finishReason: 'STOP' as any,
          index: 0,
        }],
      } as GenerateContentResponse;

      // æ·»åŠ å°å»¶è¿Ÿä»¥æ¨¡æ‹Ÿæµå¼è¾“å‡º
      await new Promise(resolve => setTimeout(resolve, 100));
    }
  }
}
